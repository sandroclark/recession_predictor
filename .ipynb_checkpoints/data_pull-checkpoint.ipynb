{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and API Key\n",
    "\n",
    "import pandas as pd\n",
    "import quandl\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%aimport dataclean\n",
    "\n",
    "quandl.ApiConfig.api_key = 'm8FYMyoCaJSbTrBASNHh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling data from Quandl\n",
    "\n",
    "data = pd.read_csv('data_for_pull.csv') #staging the QUANDL keys to pull in CSV\n",
    "cols = list(data['Var_name'].astype('str'))\n",
    "dataset = quandl.get([val for val in data['Quandl Key']]) #looping through the QUANDL keys to pull it into one DF\n",
    "dataset.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling FED Yield Curve data\n",
    "\n",
    "yields = pd.read_csv('Fed10Y_3M.csv')\n",
    "yields['Date'] = pd.to_datetime(yields['Date'])\n",
    "yields['Date'] = yields['Date'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "yields = yields.set_index('Date')\n",
    "yields = yields.drop(['3 Month Treasury Yield', 'Rec_prob', 'NBER_Rec','Unnamed: 7'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913-01-01   NaN\n",
       "1913-02-01   NaN\n",
       "1913-03-01   NaN\n",
       "1913-04-01   NaN\n",
       "1913-05-01   NaN\n",
       "1913-06-01   NaN\n",
       "1913-07-01   NaN\n",
       "1913-08-01   NaN\n",
       "1913-09-01   NaN\n",
       "1913-10-01   NaN\n",
       "1913-11-01   NaN\n",
       "1913-12-01   NaN\n",
       "1914-01-01   NaN\n",
       "1914-02-01   NaN\n",
       "1914-03-01   NaN\n",
       "1914-04-01   NaN\n",
       "1914-05-01   NaN\n",
       "1914-06-01   NaN\n",
       "1914-07-01   NaN\n",
       "1914-08-01   NaN\n",
       "1914-09-01   NaN\n",
       "1914-10-01   NaN\n",
       "1914-11-01   NaN\n",
       "1914-12-01   NaN\n",
       "1915-01-01   NaN\n",
       "1915-02-01   NaN\n",
       "1915-03-01   NaN\n",
       "1915-04-01   NaN\n",
       "1915-05-01   NaN\n",
       "1915-06-01   NaN\n",
       "              ..\n",
       "2019-02-22   NaN\n",
       "2019-02-25   NaN\n",
       "2019-02-26   NaN\n",
       "2019-02-27   NaN\n",
       "2019-02-28   NaN\n",
       "2019-03-01   NaN\n",
       "2019-03-04   NaN\n",
       "2019-03-05   NaN\n",
       "2019-03-06   NaN\n",
       "2019-03-07   NaN\n",
       "2019-03-08   NaN\n",
       "2019-03-11   NaN\n",
       "2019-03-12   NaN\n",
       "2019-03-13   NaN\n",
       "2019-03-14   NaN\n",
       "2019-03-15   NaN\n",
       "2019-03-18   NaN\n",
       "2019-03-19   NaN\n",
       "2019-03-20   NaN\n",
       "2019-03-21   NaN\n",
       "2019-03-22   NaN\n",
       "2019-03-25   NaN\n",
       "2019-03-26   NaN\n",
       "2019-03-27   NaN\n",
       "2019-03-28   NaN\n",
       "2019-03-29   NaN\n",
       "2019-03-31   NaN\n",
       "2019-04-01   NaN\n",
       "2019-04-02   NaN\n",
       "2019-04-03   NaN\n",
       "Name: GDP, Length: 15509, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## back to working on the general data\n",
    "dataset.index = dataset.index.strftime('%Y-%m') #converting the datetime index to Y/M so it is collapsable\n",
    "dataset = dataset.groupby(dataset.index, as_index=True).agg(sum) #collapsing by Y/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting GDP quarterly data into monthly - need to convert it so it fills in the following 3 months\n",
    "\n",
    "dataset = dataclean.convert_q_to_m(dataset, 'GDP')\n",
    "\n",
    "#converting consumer sentiment into monthly\n",
    "\n",
    "dataset = dataclean.convert_q_to_m(dataset, 'CONS_SENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating change in GDP and converting Y into categorical values \n",
    "dataset['Recession'] = ((dataset['GDP'] - dataset['GDP'].shift(3)) < 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge fed interest rate data here\n",
    "dataset = dataset.join(yields, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoff most of missing data, Post March 2019, Prior 1959. CPI/PPI missing 2016 onward so need to cut that off\n",
    "dataset = dataset.iloc[552:]\n",
    "dataset = dataset.iloc[:-59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Recession'] #splitting off Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_shift = y.shift(-3) #shifting y to forecast 3 months out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_shift = y_shift.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = ['GDP','Recession']) #dropping calc column and recession column from dataset, experimenting with taking out fed funds rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituting mean value in for missing values and adding dummy column to indicate where done\n",
    "\n",
    "for col in dataset.columns:\n",
    "    dataclean.clean_zeros(col, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding momentum factors\n",
    "\n",
    "momentum_cols = list(dataset.columns[:-6])\n",
    "\n",
    "momentum_cols.remove('PPI') #removing PPI and CPI because they need a different transformation\n",
    "momentum_cols.remove('CPI')\n",
    "\n",
    "for i in [1,3,12]:\n",
    "    for col in momentum_cols:\n",
    "        dataclean.create_momentum(col,dataset,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPI Calcs\n",
    "\n",
    "for i in [1,3,12]:\n",
    "    for col in ['CPI','PPI']:\n",
    "        dataclean.infl_momentum(col,dataset,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Prep Finished Here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
