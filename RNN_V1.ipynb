{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and API Key\n",
    "\n",
    "import pandas as pd\n",
    "import quandl\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "%aimport dataclean\n",
    "\n",
    "quandl.ApiConfig.api_key = 'm8FYMyoCaJSbTrBASNHh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling data from Quandl\n",
    "\n",
    "data = pd.read_csv('data_for_pull.csv') #staging the QUANDL keys to pull in CSV\n",
    "cols = list(data['Var_name'].astype('str'))\n",
    "dataset = quandl.get([val for val in data['Quandl Key']]) #looping through the QUANDL keys to pull it into one DF\n",
    "dataset.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling FED Yield Curve data\n",
    "\n",
    "yields = pd.read_csv('Fed10Y_3M.csv')\n",
    "yields['Date'] = pd.to_datetime(yields['Date'])\n",
    "yields['Date'] = yields['Date'].apply(lambda x: x.strftime('%Y-%m'))\n",
    "yields = yields.set_index('Date')\n",
    "yields = yields.drop(['3 Month Treasury Yield', 'Rec_prob', 'NBER_Rec','Unnamed: 7'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## back to working on the general data\n",
    "dataset.index = dataset.index.strftime('%Y-%m') #converting the datetime index to Y/M so it is collapsable\n",
    "dataset = dataset.groupby(dataset.index, as_index=True).agg(sum) #collapsing by Y/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting GDP quarterly data into monthly\n",
    "\n",
    "dataset = dataclean.convert_q_to_m(dataset, 'GDP')\n",
    "\n",
    "#converting consumer sentiment into monthly\n",
    "\n",
    "dataset = dataclean.convert_q_to_m(dataset, 'CONS_SENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating change in GDP and converting Y into categorical values \n",
    "dataset['Recession'] = ((dataset['GDP'] - dataset['GDP'].shift(3)) < 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge fed interest rate data here\n",
    "dataset = dataset.join(yields, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoff most of missing data, Post March 2019, Prior 1959. CPI/PPI missing 2016 onward so need to cut that off\n",
    "dataset = dataset.iloc[552:]\n",
    "dataset = dataset.iloc[:-59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Recession'] #splitting off Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = ['GDP','Recession']) #dropping calc column and recession column from dataset, experimenting with taking out fed funds rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#substituting mean value in for missing values and adding dummy column to indicate where done\n",
    "\n",
    "for col in dataset.columns:\n",
    "    dataclean.clean_zeros(col, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding momentum factors\n",
    "\n",
    "momentum_cols = list(dataset.columns[:-6])\n",
    "\n",
    "momentum_cols.remove('PPI') #removing PPI and CPI because they need a different transformation\n",
    "momentum_cols.remove('CPI')\n",
    "\n",
    "for i in [1,3,12]:\n",
    "    for col in momentum_cols:\n",
    "        dataclean.create_momentum(col,dataset,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPI Calcs\n",
    "\n",
    "for i in [1,3,12]:\n",
    "    for col in ['CPI','PPI']:\n",
    "        dataclean.infl_momentum(col,dataset,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data Prep Finished Here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = -12\n",
    "y_shift = y.shift(window) #shifting y to forecast 3 months out\n",
    "y_shift = y_shift.fillna(0)\n",
    "#time_step = window*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowize_data_x(data, n_prev):\n",
    "    n_predictions = len(data) - n_prev\n",
    "    y = data[n_prev:]\n",
    "    # this might be too clever\n",
    "    indices = np.arange(n_prev) + np.arange(n_predictions)[:, None]\n",
    "    x = data[indices, None]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_windowize_x(data, n_prev, fraction_test=0.3):\n",
    "    n_predictions = len(data) - 2*n_prev\n",
    "    \n",
    "    n_test  = int(fraction_test * n_predictions)\n",
    "    n_train = n_predictions - n_test   \n",
    "    \n",
    "    x_train, y_train = windowize_data(data[:n_train], n_prev)\n",
    "    x_test, y_test = windowize_data(data[n_train:], n_prev)\n",
    "    return x_train, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_and_windowize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-19c8d65bd054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_and_windowize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_and_windowize' is not defined"
     ]
    }
   ],
   "source": [
    "n_prev = 50\n",
    "\n",
    "x_train, x_test, y_train = split_and_windowize(X, n_prev)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[12:550]\n",
    "X_test = X.iloc[550:]\n",
    "y_train = y_shift.iloc[12:550]\n",
    "y_test = y_shift.iloc[550:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, 98)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[61.5       ,  5.2       , 10.9       , ...,  0.        ,\n",
       "          1.03448276, -0.31545741]],\n",
       "\n",
       "       [[52.3       ,  4.8       , 10.2       , ...,  0.31746032,\n",
       "          1.73010381, -0.31545741]],\n",
       "\n",
       "       [[47.8       ,  5.4       , 11.5       , ...,  0.95238095,\n",
       "          1.73010381,  0.31545741]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[58.5       ,  5.4       , 11.5       , ...,  0.81743869,\n",
       "          2.65438787,  7.24637681]],\n",
       "\n",
       "       [[57.4       ,  5.4       , 11.7       , ...,  0.33967391,\n",
       "          2.53779698,  6.64259928]],\n",
       "\n",
       "       [[56.3       ,  5.5       , 12.1       , ...,  1.76390773,\n",
       "          3.18918919,  7.68126346]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(X_train.values,(538,1,98)) #worked with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1])) #this shouldn't throw an error, X_train is 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538, 1, 98)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(32, input_shape=(1,98), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(32, return_sequences=True))\n",
    "model.add(keras.layers.LSTM(32, return_sequences=False))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy') #this is log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 1, 32)             16768     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 1, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 33,441\n",
      "Trainable params: 33,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "538/538 [==============================] - 7s 12ms/step - loss: 0.6363\n",
      "Epoch 2/100\n",
      "538/538 [==============================] - 0s 480us/step - loss: 0.4929\n",
      "Epoch 3/100\n",
      "538/538 [==============================] - 0s 516us/step - loss: 0.3204\n",
      "Epoch 4/100\n",
      "538/538 [==============================] - 0s 561us/step - loss: 0.1900\n",
      "Epoch 5/100\n",
      "538/538 [==============================] - 0s 482us/step - loss: 0.1260\n",
      "Epoch 6/100\n",
      "538/538 [==============================] - 0s 475us/step - loss: 0.1016\n",
      "Epoch 7/100\n",
      "538/538 [==============================] - 0s 482us/step - loss: 0.0931\n",
      "Epoch 8/100\n",
      "538/538 [==============================] - 0s 535us/step - loss: 0.0907\n",
      "Epoch 9/100\n",
      "538/538 [==============================] - 0s 478us/step - loss: 0.0893\n",
      "Epoch 10/100\n",
      "538/538 [==============================] - 0s 502us/step - loss: 0.0884\n",
      "Epoch 11/100\n",
      "538/538 [==============================] - 0s 526us/step - loss: 0.0873\n",
      "Epoch 12/100\n",
      "538/538 [==============================] - 0s 491us/step - loss: 0.0864\n",
      "Epoch 13/100\n",
      "538/538 [==============================] - 0s 545us/step - loss: 0.0860\n",
      "Epoch 14/100\n",
      "538/538 [==============================] - 0s 523us/step - loss: 0.0851\n",
      "Epoch 15/100\n",
      "538/538 [==============================] - 0s 548us/step - loss: 0.0848\n",
      "Epoch 16/100\n",
      "538/538 [==============================] - 0s 484us/step - loss: 0.0840\n",
      "Epoch 17/100\n",
      "538/538 [==============================] - 0s 511us/step - loss: 0.0836\n",
      "Epoch 18/100\n",
      "538/538 [==============================] - 0s 457us/step - loss: 0.0828\n",
      "Epoch 19/100\n",
      "538/538 [==============================] - 0s 487us/step - loss: 0.0826\n",
      "Epoch 20/100\n",
      "538/538 [==============================] - 0s 508us/step - loss: 0.0823\n",
      "Epoch 21/100\n",
      "538/538 [==============================] - 0s 494us/step - loss: 0.0820\n",
      "Epoch 22/100\n",
      "538/538 [==============================] - 0s 526us/step - loss: 0.0813\n",
      "Epoch 23/100\n",
      "538/538 [==============================] - 0s 489us/step - loss: 0.0813\n",
      "Epoch 24/100\n",
      "538/538 [==============================] - 0s 528us/step - loss: 0.0805\n",
      "Epoch 25/100\n",
      "538/538 [==============================] - 0s 520us/step - loss: 0.0803\n",
      "Epoch 26/100\n",
      "538/538 [==============================] - 0s 495us/step - loss: 0.0802\n",
      "Epoch 27/100\n",
      "538/538 [==============================] - 0s 529us/step - loss: 0.0798\n",
      "Epoch 28/100\n",
      "538/538 [==============================] - 0s 472us/step - loss: 0.0795\n",
      "Epoch 29/100\n",
      "538/538 [==============================] - 0s 499us/step - loss: 0.0791\n",
      "Epoch 30/100\n",
      "538/538 [==============================] - 0s 549us/step - loss: 0.0784\n",
      "Epoch 31/100\n",
      "538/538 [==============================] - 0s 485us/step - loss: 0.0788\n",
      "Epoch 32/100\n",
      "538/538 [==============================] - 0s 504us/step - loss: 0.0782\n",
      "Epoch 33/100\n",
      "538/538 [==============================] - 0s 516us/step - loss: 0.0778\n",
      "Epoch 34/100\n",
      "538/538 [==============================] - 0s 505us/step - loss: 0.0776\n",
      "Epoch 35/100\n",
      "538/538 [==============================] - 0s 519us/step - loss: 0.0773\n",
      "Epoch 36/100\n",
      "538/538 [==============================] - 0s 520us/step - loss: 0.0770\n",
      "Epoch 37/100\n",
      "538/538 [==============================] - 0s 484us/step - loss: 0.0766\n",
      "Epoch 38/100\n",
      "538/538 [==============================] - 0s 490us/step - loss: 0.0768\n",
      "Epoch 39/100\n",
      "538/538 [==============================] - 0s 485us/step - loss: 0.0762\n",
      "Epoch 40/100\n",
      "538/538 [==============================] - 0s 517us/step - loss: 0.0760\n",
      "Epoch 41/100\n",
      "538/538 [==============================] - 0s 497us/step - loss: 0.0755\n",
      "Epoch 42/100\n",
      "538/538 [==============================] - 0s 513us/step - loss: 0.0752\n",
      "Epoch 43/100\n",
      "538/538 [==============================] - 0s 506us/step - loss: 0.0750\n",
      "Epoch 44/100\n",
      "538/538 [==============================] - 0s 544us/step - loss: 0.0746\n",
      "Epoch 45/100\n",
      "538/538 [==============================] - 0s 500us/step - loss: 0.0743\n",
      "Epoch 46/100\n",
      "538/538 [==============================] - 0s 546us/step - loss: 0.0745\n",
      "Epoch 47/100\n",
      "538/538 [==============================] - 0s 500us/step - loss: 0.0737\n",
      "Epoch 48/100\n",
      "538/538 [==============================] - 0s 528us/step - loss: 0.0734\n",
      "Epoch 49/100\n",
      "538/538 [==============================] - 0s 507us/step - loss: 0.0736\n",
      "Epoch 50/100\n",
      "538/538 [==============================] - 0s 519us/step - loss: 0.0730\n",
      "Epoch 51/100\n",
      "538/538 [==============================] - 0s 543us/step - loss: 0.0724\n",
      "Epoch 52/100\n",
      "538/538 [==============================] - 0s 556us/step - loss: 0.0723\n",
      "Epoch 53/100\n",
      "538/538 [==============================] - 0s 533us/step - loss: 0.0720\n",
      "Epoch 54/100\n",
      "538/538 [==============================] - 0s 517us/step - loss: 0.0723\n",
      "Epoch 55/100\n",
      "538/538 [==============================] - 0s 562us/step - loss: 0.0716\n",
      "Epoch 56/100\n",
      "538/538 [==============================] - 0s 518us/step - loss: 0.0710\n",
      "Epoch 57/100\n",
      "538/538 [==============================] - 0s 532us/step - loss: 0.0708\n",
      "Epoch 58/100\n",
      "538/538 [==============================] - 0s 550us/step - loss: 0.0710\n",
      "Epoch 59/100\n",
      "538/538 [==============================] - 0s 534us/step - loss: 0.0706\n",
      "Epoch 60/100\n",
      "538/538 [==============================] - 0s 521us/step - loss: 0.0707\n",
      "Epoch 61/100\n",
      "538/538 [==============================] - 0s 525us/step - loss: 0.0701\n",
      "Epoch 62/100\n",
      "538/538 [==============================] - 0s 557us/step - loss: 0.0708\n",
      "Epoch 63/100\n",
      "538/538 [==============================] - 0s 520us/step - loss: 0.0698\n",
      "Epoch 64/100\n",
      "538/538 [==============================] - 0s 525us/step - loss: 0.0698\n",
      "Epoch 65/100\n",
      "538/538 [==============================] - 0s 542us/step - loss: 0.0695\n",
      "Epoch 66/100\n",
      "538/538 [==============================] - 0s 534us/step - loss: 0.0694\n",
      "Epoch 67/100\n",
      "538/538 [==============================] - 0s 572us/step - loss: 0.0687\n",
      "Epoch 68/100\n",
      "538/538 [==============================] - 0s 569us/step - loss: 0.0689\n",
      "Epoch 69/100\n",
      "538/538 [==============================] - 0s 572us/step - loss: 0.0688\n",
      "Epoch 70/100\n",
      "538/538 [==============================] - 0s 572us/step - loss: 0.0684\n",
      "Epoch 71/100\n",
      "538/538 [==============================] - 0s 541us/step - loss: 0.0681\n",
      "Epoch 72/100\n",
      "538/538 [==============================] - 0s 569us/step - loss: 0.0681\n",
      "Epoch 73/100\n",
      "538/538 [==============================] - 0s 567us/step - loss: 0.0676\n",
      "Epoch 74/100\n",
      "538/538 [==============================] - 0s 569us/step - loss: 0.0678\n",
      "Epoch 75/100\n",
      "538/538 [==============================] - 0s 571us/step - loss: 0.0677\n",
      "Epoch 76/100\n",
      "538/538 [==============================] - 0s 576us/step - loss: 0.0678\n",
      "Epoch 77/100\n",
      "538/538 [==============================] - 0s 559us/step - loss: 0.0674\n",
      "Epoch 78/100\n",
      "538/538 [==============================] - 0s 568us/step - loss: 0.0674\n",
      "Epoch 79/100\n",
      "538/538 [==============================] - 0s 568us/step - loss: 0.0673\n",
      "Epoch 80/100\n",
      "538/538 [==============================] - 0s 586us/step - loss: 0.0669\n",
      "Epoch 81/100\n",
      "538/538 [==============================] - 0s 582us/step - loss: 0.0674\n",
      "Epoch 82/100\n",
      "538/538 [==============================] - 0s 587us/step - loss: 0.0667\n",
      "Epoch 83/100\n",
      "538/538 [==============================] - 0s 586us/step - loss: 0.0669\n",
      "Epoch 84/100\n",
      "538/538 [==============================] - 0s 577us/step - loss: 0.0664\n",
      "Epoch 85/100\n",
      "538/538 [==============================] - 0s 591us/step - loss: 0.0666\n",
      "Epoch 86/100\n",
      "538/538 [==============================] - 0s 574us/step - loss: 0.0676\n",
      "Epoch 87/100\n",
      "538/538 [==============================] - 0s 598us/step - loss: 0.0664\n",
      "Epoch 88/100\n",
      "538/538 [==============================] - 0s 589us/step - loss: 0.0669\n",
      "Epoch 89/100\n",
      "538/538 [==============================] - 0s 595us/step - loss: 0.0665\n",
      "Epoch 90/100\n",
      "538/538 [==============================] - 0s 602us/step - loss: 0.0662\n",
      "Epoch 91/100\n",
      "538/538 [==============================] - 0s 602us/step - loss: 0.0670\n",
      "Epoch 92/100\n",
      "538/538 [==============================] - 0s 603us/step - loss: 0.0664\n",
      "Epoch 93/100\n",
      "538/538 [==============================] - 0s 604us/step - loss: 0.0660\n",
      "Epoch 94/100\n",
      "538/538 [==============================] - 0s 607us/step - loss: 0.0661\n",
      "Epoch 95/100\n",
      "538/538 [==============================] - 0s 605us/step - loss: 0.0666\n",
      "Epoch 96/100\n",
      "538/538 [==============================] - 0s 598us/step - loss: 0.0666\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "538/538 [==============================] - 0s 558us/step - loss: 0.0663\n",
      "Epoch 98/100\n",
      "538/538 [==============================] - 0s 500us/step - loss: 0.0663\n",
      "Epoch 99/100\n",
      "538/538 [==============================] - 0s 518us/step - loss: 0.0665\n",
      "Epoch 100/100\n",
      "538/538 [==============================] - 0s 597us/step - loss: 0.0663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4092f5c0>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, y_train.values, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1])) #this shouldn't throw an error, X_train is 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42303303799941205"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7503687315634219"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
